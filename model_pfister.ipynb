{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_csv('data/movies_meta_data.csv', sep=';', engine='python')\n",
    "users = pd.read_csv('data/users.dat', sep='::', engine='python', names=['userId', 'gender', 'age', 'occupation', 'zip-code'])\n",
    "ratings = pd.read_csv('data/ratings.dat', sep='::', engine='python', names=['userId', 'movieId', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.groupby('gender').size().plot(kind='pie', y=0, figsize=(10, 10), autopct='%1.1f%%', title='Gender distribution')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.groupby('userId').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.groupby('userId').size().plot(kind='hist', bins=100, figsize=(5, 5), title='Number of ratings per user', xlabel='Number of ratings', ylabel='Number of users')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we don't plan on doing anything with the zip code of the user we will drop this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dropped = users.drop(['zip-code'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the timestamp adds no value to our model we are going to remove the timestamp from all ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_dropped = ratings.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dropped = movies[['ml_movieId', 'Title', 'Year', 'Released', 'Runtime', 'Genre', 'Ratings', 'Metascore', 'imdbRating', 'imdbVotes', 'BoxOffice']]\n",
    "movies_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Fill missing 'imdbRating' values with the mean\n",
    "movies_dropped['imdbRating'].fillna(movies_dropped['imdbRating'].mean(), inplace=True)\n",
    "\n",
    "# Round the 'imdbRating' values to one decimal place\n",
    "movies_dropped['imdbRating'] = movies_dropped['imdbRating'].round(decimals=1)\n",
    "\n",
    "# Convert the 'imdbVotes' column to float type using regular expressions\n",
    "movies_dropped['imdbVotes'] = movies_dropped['imdbVotes'].apply(lambda x: float(re.sub(r'[^\\d.]', '', x)) if isinstance(x, str) else x)\n",
    "\n",
    "# Fill in missing values with mean\n",
    "movies_dropped['imdbVotes'].fillna(movies_dropped['imdbVotes'].mean(), inplace=True)\n",
    "\n",
    "# Round the 'imdbVotes' values to zero decimal places\n",
    "movies_dropped['imdbVotes'] = movies_dropped['imdbVotes'].round(decimals=0)\n",
    "\n",
    "# Convert the 'BoxOffice' column to float type using regular expressions\n",
    "movies_dropped['BoxOffice'] = movies_dropped['BoxOffice'].apply(lambda x: float(re.sub(r'[^\\d.]', '', x)) if isinstance(x, str) else x)\n",
    "\n",
    "# Fill in missing values with mean\n",
    "movies_dropped['BoxOffice'].fillna(movies_dropped['BoxOffice'].mean(), inplace=True)\n",
    "\n",
    "# Round the 'BoxOffice' values to zero decimal places\n",
    "movies_dropped['BoxOffice'] = movies_dropped['BoxOffice'].round(decimals=0)\n",
    "\n",
    "# Convert the 'Runtime' column from minutes to hours\n",
    "movies_dropped['Runtime'] = movies_dropped['Runtime'].apply(lambda x: int(re.sub(r'\\D', '', x)) / 60 if isinstance(x, str) else x)\n",
    "\n",
    "# Fill in missing values with mean\n",
    "movies_dropped['Runtime'].fillna(movies_dropped['Runtime'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values by selecting only rows without NaN values in the 'Released' column\n",
    "movies_dropped = movies_dropped.loc[~pd.isna(movies_dropped['Released'])]\n",
    "movies_dropped['Released'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with missing values in the 'Genre' column\n",
    "movies_dropped.dropna(subset=['Genre'], inplace=True)\n",
    "movies_dropped['Genre'].isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map numeric occupation values to text labels\n",
    "occupation_labels = {\n",
    "    0: \"other or not specified\",\n",
    "    1: \"academic/educator\",\n",
    "    2: \"artist\",\n",
    "    3: \"clerical/admin\",\n",
    "    4: \"college/grad student\",\n",
    "    5: \"customer service\",\n",
    "    6: \"doctor/health care\",\n",
    "    7: \"executive/managerial\",\n",
    "    8: \"farmer\",\n",
    "    9: \"homemaker\",\n",
    "    10: \"K-12 student\",\n",
    "    11: \"lawyer\",\n",
    "    12: \"programmer\",\n",
    "    13: \"retired\",\n",
    "    14: \"sales/marketing\",\n",
    "    15: \"scientist\",\n",
    "    16: \"self-employed\",\n",
    "    17: \"technician/engineer\",\n",
    "    18: \"tradesman/craftsman\",\n",
    "    19: \"unemployed\",\n",
    "    20: \"writer\",\n",
    "}\n",
    "\n",
    "# Replace the numeric occupation values with text labels using the map method\n",
    "users_dropped[\"occupation\"] = users[\"occupation\"].map(occupation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_labels = {\n",
    "    1: \"Under 18\",\n",
    "    18: \"18-24\",\n",
    "    25: \"25-34\",\n",
    "    35: \"35-44\",\n",
    "    45: \"45-49\",\n",
    "    50: \"50-55\",\n",
    "    56: \"56+\",\n",
    "}\n",
    "\n",
    "# Replace the numeric age values with text labels using the map method\n",
    "users_dropped[\"age\"] = users[\"age\"].map(age_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dropped.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'ml_movieId' column to 'movieId'\n",
    "movies_dropped.rename(columns={'ml_movieId': 'movieId'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = movies_dropped.merge(ratings_dropped, on='movieId', how='left')\n",
    "# merged['userId'] = merged['userId'].astype('int32')\n",
    "merged.isna().sum()\n",
    "# merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD approach with Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset, SVD, accuracy, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "model = SVD()\n",
    "data = Dataset.load_from_df(ratings_dropped, Reader(rating_scale=(1, 5)))\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/models/SVD_Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[362], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Dump algorithm and reload it.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/models/SVD_Model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m dump\u001b[39m.\u001b[39;49mdump(file_name, algo\u001b[39m=\u001b[39;49mmodel)\n\u001b[0;32m      6\u001b[0m _, loaded_algo \u001b[39m=\u001b[39m dump\u001b[39m.\u001b[39mload(file_name)\n",
      "File \u001b[1;32mc:\\Users\\domin\\VSC Workspace\\morebo\\venv\\Lib\\site-packages\\surprise\\dump.py:28\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(file_name, predictions, algo, verbose)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"A basic wrapper around Pickle to serialize a list of prediction and/or\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39man algorithm on drive.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m        that the dumping went successfully. Default is ``0``.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m dump_obj \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mpredictions\u001b[39m\u001b[39m\"\u001b[39m: predictions, \u001b[39m\"\u001b[39m\u001b[39malgo\u001b[39m\u001b[39m\"\u001b[39m: algo}\n\u001b[1;32m---> 28\u001b[0m pickle\u001b[39m.\u001b[39mdump(dump_obj, \u001b[39mopen\u001b[39;49m(file_name, \u001b[39m\"\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m\"\u001b[39;49m), protocol\u001b[39m=\u001b[39mpickle\u001b[39m.\u001b[39mHIGHEST_PROTOCOL)\n\u001b[0;32m     30\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[0;32m     31\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe dump has been saved as file\u001b[39m\u001b[39m\"\u001b[39m, file_name)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/models/SVD_Model'"
     ]
    }
   ],
   "source": [
    "from surprise import dump\n",
    "\n",
    "# Dump algorithm and reload it.\n",
    "file_name = 'models/SVD_Model'\n",
    "dump.dump(file_name, algo=model)\n",
    "_, loaded_algo = dump.load(file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling a new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_user_id = 9999\n",
    "new_user_movies = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "new_user_ratings = [5, 4, 3, 2, 1, 5, 4, 3, 2, 1]\n",
    "\n",
    "new_user = pd.DataFrame({'userId': new_user_id, 'movieId': new_user_movies, 'rating': new_user_ratings})\n",
    "ratings_combined = pd.concat([ratings_dropped, new_user], ignore_index=True)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings_combined, reader)\n",
    "\n",
    "# Retrain the model with the combined ratings data\n",
    "model = SVD()\n",
    "trainset = data.build_full_trainset()\n",
    "model.fit(trainset)\n",
    "\n",
    "model.predict(uid=new_user_id, iid=3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation with pearson similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = merged.pivot_table(index=['userId'], columns=['Title'], values='rating')\n",
    "pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pivot.dropna(thresh=10, axis=1).fillna(0)\n",
    "pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df = pivot.corr(method='pearson')\n",
    "similarity_df.head()\n",
    "similarity_df.to_csv('data/similarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_movies(title, user_rating):\n",
    "    similar_score = similarity_df[title]*(user_rating-2.5)\n",
    "    similar_score = similar_score.sort_values(ascending=False)\n",
    "    \n",
    "    return similar_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_lover = [(\"Jurassic Park\", 5), (\"The Lost World: Jurassic Park\", 5), ('Titanic', 3), ('Forrest Gump', 5)]\n",
    "similar_movies = pd.DataFrame()\n",
    "\n",
    "for movie, rating in action_lover:\n",
    "    similar_movies = similar_movies.append(get_similar_movies(movie, rating), ignore_index=True)\n",
    "\n",
    "similar_movies.head()\n",
    "similar_movies.sum().sort_values(ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
