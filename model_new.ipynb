{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearm.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from tensorflow.keras import models, layers, utils, optimizers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('data/movies.dat', sep='::', engine='python', names=['movieId', 'title', 'genres'],encoding='latin1')\n",
    "users_df = pd.read_csv('data/users.dat', sep='::', engine='python', names=['userId', 'gender', 'age', 'occupation', 'zip-code'])\n",
    "ratings_df = pd.read_csv('data/ratings.dat', sep='::', engine='python', names=['userId', 'movieId', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df[~movies_df[\"genres\"].isna()]\n",
    "movies_df[\"product\"] = range(0, len(movies_df))\n",
    "movies_df[\"name\"] = movies_df[\"title\"].apply(lambda x: re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", x).strip())\n",
    "movies_df[\"date\"] = movies_df[\"title\"].apply(lambda x: int(x.split(\"(\")[-1].replace(\")\", \"\").strip()) if \"(\" in x else np.nan)\n",
    "movies_df[\"date\"] = movies_df[\"date\"].fillna(9999)\n",
    "movies_df[\"old\"] = movies_df[\"date\"].apply(lambda x: 1 if x < 2000 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df[\"user\"] = ratings_df[\"userId\"].apply(lambda x: x-1)\n",
    "ratings_df[\"timestamp\"] = ratings_df[\"timestamp\"].apply(lambda x: datetime.fromtimestamp(x))\n",
    "ratings_df[\"daytime\"] = ratings_df[\"timestamp\"].apply(lambda x: 1 if 6 < int(x.strftime(\"%H\")) < 20 else 0)\n",
    "ratings_df[\"weekend\"] = ratings_df[\"timestamp\"].apply(lambda x: 1 if x.weekday() in [5, 6] else 0)\n",
    "ratings_df = ratings_df.merge(movies_df[[\"movieId\", \"product\"]], how=\"left\")\n",
    "ratings_df = ratings_df.rename(columns={\"rating\": \"y\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df[[\"product\",\"name\",\"old\",\"genres\"]].set_index(\"product\")\n",
    "ratings_df = ratings_df[[\"user\",\"product\",\"daytime\",\"weekend\",\"y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_df = ratings_df[[\"user\",\"product\",\"daytime\",\"weekend\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [i.split(\"|\") for i in movies_df[\"genres\"].unique()]\n",
    "columns = list(set([i for lst in tags for i in lst]))\n",
    "\n",
    "if '(no genres listed)' in columns:\n",
    "    columns.remove('(no genres listed)')\n",
    "\n",
    "for col in columns:\n",
    "    movies_df[col] = movies_df[\"genres\"].apply(lambda x: 1 if col in x else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.heatmap(movies_df==0, vmin=0, vmax=1, cbar=False, ax=ax).set_title(\"Movies x Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ratings_df.copy()\n",
    "ratings_df = tmp.pivot_table(index=\"user\", columns=\"product\", values=\"y\")\n",
    "missing_cols = list(set(ratings_df.index) - set(ratings_df.columns))\n",
    "for col in missing_cols:\n",
    "    ratings_df[col] = np.nan\n",
    "ratings_df = ratings_df[sorted(ratings_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.DataFrame(preprocessing.MinMaxScaler(feature_range=(0.5,1)).fit_transform(ratings_df.values), \n",
    "columns=ratings_df.columns, index=ratings_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8*ratings_df.shape[1])\n",
    "train_df = ratings_df.loc[:, :split-1]\n",
    "test_df = ratings_df.loc[:, split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = movies_df.drop([\"genres\",\"name\"], axis=1).columns\n",
    "print(features)\n",
    "context = context_df.drop([\"user\",\"product\"], axis=1).columns\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.stack(dropna=True).reset_index().rename(columns={0:\"y\"})\n",
    "## add features\n",
    "train = train.merge(movies_df[features], how=\"left\", left_on=\"product\", right_index=True)\n",
    "## add context\n",
    "train = train.merge(context_df, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df.stack(dropna=True).reset_index().rename(columns={0:\"y\"})\n",
    "## add features\n",
    "test = test.merge(movies_df[features], how=\"left\", left_on=\"product\", right_index=True)\n",
    "## add context\n",
    "test = test.merge(context_df, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_size = 50\n",
    "usr, prd = ratings_df.shape[0], ratings_df.shape[1]\n",
    "feat = len(features)\n",
    "ctx = len(context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "xusers_in = layers.Input(name=\"xusers_in\", shape=(1,))\n",
    "xproducts_in = layers.Input(name=\"xproducts_in\", shape=(1,))# A) Matrix Factorization\n",
    "## embeddings and reshape\n",
    "cf_xusers_emb = layers.Embedding(name=\"cf_xusers_emb\", input_dim=usr, output_dim=embeddings_size)(xusers_in)\n",
    "cf_xusers = layers.Reshape(name='cf_xusers', target_shape=(embeddings_size,))(cf_xusers_emb)## embeddings and reshape\n",
    "cf_xproducts_emb = layers.Embedding(name=\"cf_xproducts_emb\", input_dim=prd, output_dim=embeddings_size)(xproducts_in)\n",
    "cf_xproducts = layers.Reshape(name='cf_xproducts', target_shape=(embeddings_size,))(cf_xproducts_emb)## product\n",
    "cf_xx = layers.Dot(name='cf_xx', normalize=True, axes=1)([cf_xusers, cf_xproducts])# B) Neural Network\n",
    "## embeddings and reshape\n",
    "nn_xusers_emb = layers.Embedding(name=\"nn_xusers_emb\", input_dim=usr, output_dim=embeddings_size)(xusers_in)\n",
    "nn_xusers = layers.Reshape(name='nn_xusers', target_shape=(embeddings_size,))(nn_xusers_emb)## embeddings and reshape\n",
    "nn_xproducts_emb = layers.Embedding(name=\"nn_xproducts_emb\", input_dim=prd, output_dim=embeddings_size)(xproducts_in)\n",
    "nn_xproducts = layers.Reshape(name='nn_xproducts', target_shape=(embeddings_size,))(nn_xproducts_emb)## concat and dense\n",
    "nn_xx = layers.Concatenate()([nn_xusers, nn_xproducts])\n",
    "nn_xx = layers.Dense(name=\"nn_xx\", units=int(embeddings_size/2), activation='relu')(nn_xx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Features\n",
    "features_in = layers.Input(name=\"features_in\", shape=(feat,))\n",
    "features_x = layers.Dense(name=\"features_x\", units=feat, activation='relu')(features_in)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context\n",
    "contexts_in = layers.Input(name=\"contexts_in\", shape=(ctx,))\n",
    "context_x = layers.Dense(name=\"context_x\", units=ctx, activation='relu')(contexts_in)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all\n",
    "y_out = layers.Concatenate()([cf_xx, nn_xx, features_x, context_x])\n",
    "y_out = layers.Dense(name=\"y_out\", units=1, activation='linear')(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model = models.Model(inputs=[xusers_in,xproducts_in, features_in, contexts_in], outputs=y_out, name=\"Hybrid_Model\")\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "training = model.fit(x=[train[\"user\"], train[\"product\"], train[features], train[context]], y=train[\"y\"], epochs=100, batch_size=128, shuffle=True, verbose=0, validation_split=0.3)\n",
    "\n",
    "model = training.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test[\"yhat\"] = model.predict([test[\"user\"], test[\"product\"], test[features], test[context]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mean Absolute Error\n",
    "mae = mean_absolute_error(test['y'], test['yhat'])\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "\n",
    "# Calculate Root Mean Squared Error\n",
    "rmse = np.sqrt(mean_squared_error(test['y'], test['yhat']))\n",
    "print(f'Root Mean Squared Error: {rmse:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
