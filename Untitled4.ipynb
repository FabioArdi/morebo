{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SDXrQeTbEiJq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import datetime\n",
        "from sklearn import metrics, preprocessing\n",
        "from tensorflow.keras import models, layers, utils, callbacks\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "# from google.colab import files\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "qm9FIBa0EmB6",
        "outputId": "33c35024-7d83-4c2c-9f58-6ce3b37cca84"
      },
      "outputs": [],
      "source": [
        "# movie = files.upload()\n",
        "# ratings = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwdyoRkbEoNq"
      },
      "outputs": [],
      "source": [
        "# movies_df = pd.read_csv(io.BytesIO(movie['movies.csv']))\n",
        "# ratings_df = pd.read_csv(io.BytesIO(ratings['ratings.csv']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "movies_df = pd.read_csv('data/movies.dat', sep='::', engine='python', names=['movieId', 'title', 'genres'], encoding='latin-1')\n",
        "users = pd.read_csv('data/users.dat', sep='::', engine='python', names=['userId', 'gender', 'age', 'occupation', 'zip-code'])\n",
        "ratings_df = pd.read_csv('data/ratings.dat', sep='::', engine='python', names=['userId', 'movieId', 'rating', 'timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwNsRHG4GMx9"
      },
      "outputs": [],
      "source": [
        "# Products\n",
        "movies_df = movies_df[~movies_df[\"genres\"].isna()]\n",
        "movies_df[\"product\"] = range(0, len(movies_df))\n",
        "movies_df[\"name\"] = movies_df[\"title\"].apply(lambda x: re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", x).strip())\n",
        "movies_df[\"date\"] = movies_df[\"title\"].apply(lambda x: int(x.split(\"(\")[-1].replace(\")\", \"\").strip()) if \"(\" in x else np.nan)\n",
        "movies_df[\"date\"] = movies_df[\"date\"].fillna(9999)\n",
        "movies_df[\"old\"] = movies_df[\"date\"].apply(lambda x: 1 if x < 2000 else 0)\n",
        "\n",
        "# Users\n",
        "ratings_df[\"user\"] = ratings_df[\"userId\"].apply(lambda x: x - 1)\n",
        "ratings_df[\"timestamp\"] = ratings_df[\"timestamp\"].apply(lambda x: datetime.fromtimestamp(x))\n",
        "ratings_df[\"daytime\"] = ratings_df[\"timestamp\"].apply(lambda x: 1 if 6 < int(x.strftime(\"%H\")) < 20 else 0)\n",
        "ratings_df[\"weekend\"] = ratings_df[\"timestamp\"].apply(lambda x: 1 if x.weekday() in [5, 6] else 0)\n",
        "ratings_df = ratings_df.merge(movies_df[[\"movieId\", \"product\"]], how=\"left\")\n",
        "ratings_df = ratings_df.rename(columns={\"rating\": \"y\"})\n",
        "\n",
        "# Clean\n",
        "movies_df = movies_df[[\"product\", \"name\", \"old\", \"genres\"]].set_index(\"product\")\n",
        "\n",
        "ratings_df = ratings_df[[\"user\", \"product\", \"daytime\", \"weekend\", \"y\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_F7SQnnJGNrb"
      },
      "outputs": [],
      "source": [
        "dtf_context = ratings_df[[\"user\", \"product\", \"daytime\", \"weekend\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYFqmxmOGPR3"
      },
      "outputs": [],
      "source": [
        "tags = [i.split(\"|\") for i in movies_df[\"genres\"].unique()]\n",
        "columns = list(set([i for lst in tags for i in lst]))\n",
        "if '(no genres listed)' in columns:\n",
        "    columns.remove('(no genres listed)')\n",
        "    \n",
        "for col in columns:\n",
        "    movies_df[col] = movies_df[\"genres\"].apply(lambda x: 1 if col in x else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "GDEkVPcmGRV9",
        "outputId": "eb2d400b-20f0-468c-c3ca-e9cc88ac854a"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 5))\n",
        "sns.heatmap(movies_df == 0, vmin=0, vmax=1, cbar=False, ax=ax).set_title(\"Products x Features\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AATIls5MGTPK",
        "outputId": "1b22b0fe-a49d-4ef2-b165-32f9270e3c47"
      },
      "outputs": [],
      "source": [
        "tmp = ratings_df.copy()\n",
        "ratings_df = tmp.pivot_table(index=\"user\", columns=\"product\", values=\"y\")\n",
        "missing_cols = list(set(movies_df.index) - set(ratings_df.columns))\n",
        "for col in missing_cols:\n",
        "    ratings_df[col] = np.nan\n",
        "ratings_df = ratings_df[sorted(ratings_df.columns)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXk0ZYjTGrGN",
        "outputId": "0b8a3b00-1d62-4bd8-bcf2-953bb8b5cfcb"
      },
      "outputs": [],
      "source": [
        "ratings_df = pd.DataFrame(preprocessing.MinMaxScaler(feature_range=(0.5, 1)).fit_transform(ratings_df.values),\n",
        "                          columns=ratings_df.columns, index=ratings_df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szu0AA0cILDz",
        "outputId": "d00bdc43-b3d1-4585-f122-6fde850fab89"
      },
      "outputs": [],
      "source": [
        "features = movies_df.drop([\"genres\", \"name\"], axis=1).columns\n",
        "print(features)\n",
        "\n",
        "context = dtf_context.drop([\"user\", \"product\"], axis=1).columns\n",
        "print(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEprTklWGs7B"
      },
      "outputs": [],
      "source": [
        "\n",
        "split = int(0.8 * ratings_df.shape[1])\n",
        "dtf_train = ratings_df.loc[:, :split-1]\n",
        "dtf_test = ratings_df.loc[:, split:]\n",
        "train = ratings_df.stack(dropna=True).reset_index().rename(columns={0: \"y\"})\n",
        "\n",
        "# Add features\n",
        "train = train.merge(movies_df[features], how=\"left\", left_on=\"product\", right_index=True)\n",
        "\n",
        "# Add context\n",
        "train = train.merge(dtf_context, how=\"left\")\n",
        "\n",
        "test = dtf_test.stack(dropna=True).reset_index().rename(columns={0: \"y\"})\n",
        "\n",
        "# Add features\n",
        "test = test.merge(movies_df[features], how=\"left\", left_on=\"product\", right_index=True)\n",
        "\n",
        "# Insert static values for context variables\n",
        "test[\"daytime\"] = 0\n",
        "test[\"weekend\"] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJxi4nEnIQ29"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    \"\"\"\n",
        "    Build and compile the hybrid recommendation model.\n",
        "    \"\"\"\n",
        "    embeddings_size = 50\n",
        "    number_of_users, number_of_products = ratings_df.shape[0], ratings_df.shape[1]\n",
        "    number_of_features = len(features)\n",
        "    number_of_contexts = len(context)\n",
        "\n",
        "    def create_embedding_block(input_layer, name, input_dim, output_dim=embeddings_size):\n",
        "        \"\"\"\n",
        "        Create an embedding block for a given input layer.\n",
        "        \"\"\"\n",
        "        embeddings = layers.Embedding(name=f\"{name}_emb\", input_dim=input_dim, output_dim=output_dim)(input_layer)\n",
        "        reshaped = layers.Reshape(name=f'{name}', target_shape=(output_dim,))(embeddings)\n",
        "        return reshaped\n",
        "\n",
        "    # COLLABORATIVE FILTERING \n",
        "    # Input layer\n",
        "    user_input = layers.Input(name=\"user_input\", shape=(1,))\n",
        "    product_input = layers.Input(name=\"product_input\", shape=(1,))\n",
        "\n",
        "    # Matrix Factorization\n",
        "    cf_users = create_embedding_block(user_input, \"cf_users\", number_of_users)\n",
        "    cf_products = create_embedding_block(product_input, \"cf_products\", number_of_products)\n",
        "    cf_output = layers.Dot(name='cf_output', normalize=True, axes=1)([cf_users, cf_products])\n",
        "\n",
        "    # Neural Network\n",
        "    nn_users = create_embedding_block(user_input, \"nn_users\", number_of_users)\n",
        "    nn_products = create_embedding_block(product_input, \"nn_products\", number_of_products)\n",
        "    nn_concat = layers.Concatenate()([nn_users, nn_products])\n",
        "    nn_output = layers.Dense(name=\"nn_output\", units=int(embeddings_size/2), activation='relu')(nn_concat)\n",
        "\n",
        "    # CONTENT BASED\n",
        "    # Product Features\n",
        "    features_input = layers.Input(name=\"features_input\", shape=(number_of_features,))\n",
        "    features_output = layers.Dense(name=\"features_output\", units=number_of_features, activation='relu')(features_input)\n",
        "\n",
        "    # KNOWLEDGE BASED\n",
        "    # Context\n",
        "    context_input = layers.Input(name=\"context_input\", shape=(number_of_contexts,))\n",
        "    context_output = layers.Dense(name=\"context_output\", units=number_of_contexts, activation='relu')(context_input)\n",
        "\n",
        "    # OUTPUT\n",
        "    # Merge all\n",
        "    final_output = layers.Concatenate()([cf_output, nn_output, features_output, context_output])\n",
        "    final_output = layers.Dense(name=\"final_output\", units=1, activation='linear')(final_output)\n",
        "\n",
        "    \n",
        "\n",
        "    # Compile\n",
        "    model = models.Model(inputs=[user_input, product_input, features_input, context_input], outputs=final_output, name=\"Hybrid_Model\")\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mean_absolute_percentage_error'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxQ6LYkPIT-2"
      },
      "outputs": [],
      "source": [
        "def train_model(model):\n",
        "  # Define early stopping\n",
        "  early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "  model.fit(x=[train[\"user\"], train[\"product\"], train[features], train[context]], y=train[\"y\"], \n",
        "                     epochs=100, batch_size=128, shuffle=True, verbose=0, validation_split=0.3,callbacks=[early_stopping])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZpU3lPmJCiM"
      },
      "outputs": [],
      "source": [
        "def mean_reciprocal_rank(y_test, predicted):\n",
        "    score = []\n",
        "    for product in y_test:\n",
        "        mrr = 1 / (list(predicted).index(product) + 1) if product in predicted else 0\n",
        "        score.append(mrr)\n",
        "    return np.mean(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-x09MweJI_S"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, i):\n",
        "    # Subset the test data for user i\n",
        "    test_user_i = test[test[\"user\"] == i]\n",
        "    \n",
        "    # Make predictions for user i\n",
        "    test_user_i[\"yhat\"] = model.predict([test_user_i[\"user\"], test_user_i[\"product\"], test_user_i[features], test_user_i[context]])\n",
        "    \n",
        "    print(\"--- user\", i, \"---\")\n",
        "    top = 5\n",
        "    y_test = test_user_i.sort_values(\"y\", ascending=False)[\"product\"].values[:top]\n",
        "    print(\"y_test:\", y_test)\n",
        "    \n",
        "    predicted = test_user_i.sort_values(\"yhat\", ascending=False)[\"product\"].values[:top]\n",
        "    print(\"predicted:\", predicted)\n",
        "    \n",
        "    true_positive = len(list(set(y_test) & set(predicted)))\n",
        "    print(\"true positive:\", true_positive, \"(\"+str(round(true_positive/top*100,1))+\"%)\")\n",
        "    \n",
        "    # Accuracy might not make sense for this kind of problem because it's not a classification problem.\n",
        "    #print(\"accuracy:\", str(round(metrics.accuracy_score(y_test,predicted)*100,1))+\"%\")\n",
        "    \n",
        "    print(\"mrr:\", mean_reciprocal_rank(y_test, predicted))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xGiBLTcOWuu"
      },
      "outputs": [],
      "source": [
        "#takes about 6 minutes\n",
        "model = build_model()\n",
        "model = train_model(model)                                            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtLdajYpP2XW"
      },
      "outputs": [],
      "source": [
        "# Assuming that 'model' is your trained model.\n",
        "model.save('recommendation_model.h5')  # creates a HDF5 file 'my_model.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ILOLDRkQAqq"
      },
      "outputs": [],
      "source": [
        "model1 = load_model('recommendation_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkT8ah1-QM3W",
        "outputId": "120f577b-f77f-4670-c621-0f948be181fc"
      },
      "outputs": [],
      "source": [
        "evaluate_model(model1,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AidOXnDfccxB"
      },
      "outputs": [],
      "source": [
        "def train_model2(model):\n",
        "  # Define early stopping\n",
        " # early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "  model.fit(x=[train[\"user\"], train[\"product\"], train[features], train[context]], y=train[\"y\"], \n",
        "                     epochs=100, batch_size=128, shuffle=True, verbose=0, validation_split=0.3)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40Gs0xcfUr47"
      },
      "outputs": [],
      "source": [
        "model = build_model()\n",
        "model = train_model2(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vnH6lb2cWo2"
      },
      "outputs": [],
      "source": [
        "# Assuming that 'model' is your trained model.\n",
        "model.save('recommendation_model2.h5')  # creates a HDF5 file 'my_model.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_QvEddscjoJ"
      },
      "outputs": [],
      "source": [
        "model2 = load_model('/content/recommendation_model2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7I9_OAYcpAS",
        "outputId": "ff5ef3dc-21e5-430e-9cc9-416627b1e0e1"
      },
      "outputs": [],
      "source": [
        "evaluate_model(model2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX9j7bLxdpAr"
      },
      "outputs": [],
      "source": [
        "def train_model3(model):\n",
        "  # Define early stopping\n",
        "  early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "  model.fit(x=[train[\"user\"], train[\"product\"], train[features], train[context]], y=train[\"y\"], \n",
        "                     epochs=100, batch_size=128, shuffle=True, verbose=0, validation_split=0.3,callbacks=[early_stopping])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_kUzmyMUmtQ"
      },
      "outputs": [],
      "source": [
        "# Training takes 18 minutes\n",
        "model = build_model()\n",
        "model = train_model3(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkVQKb9Hdw-i"
      },
      "outputs": [],
      "source": [
        "model.save('recommendation_model3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJSEp-aMd2-A"
      },
      "outputs": [],
      "source": [
        "model3 = load_model('recommendation_model3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-uETcasd8sP",
        "outputId": "fb05c0d8-5349-4a32-c3a2-f3159e630712"
      },
      "outputs": [],
      "source": [
        "evaluate_model(model3,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ratings_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ratings_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction import FeatureHasher\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_new_user(ratings_df, new_user_ratings):\n",
        "    # Convert new user ratings to a pandas series\n",
        "    new_user_series = pd.Series(new_user_ratings, name=ratings_df.shape[0])\n",
        "    \n",
        "    # Append the new user ratings to the ratings dataframe\n",
        "    updated_ratings_df = ratings_df.concat(new_user_series)\n",
        "    \n",
        "    # Fill NaNs with 0\n",
        "    updated_ratings_df.fillna(0, inplace=True)\n",
        "\n",
        "    # Get the user_id of the new user\n",
        "    new_user_id = updated_ratings_df.index[-1]\n",
        "    \n",
        "    return updated_ratings_df, new_user_id\n",
        "\n",
        "def preprocess_data(ratings_df, movies_df):\n",
        "    # Convert movies_df index to int for proper merging\n",
        "    movies_df.index = movies_df.index.astype(int)\n",
        "    \n",
        "    # Reset index\n",
        "    ratings_df.reset_index(inplace=True)\n",
        "    ratings_df = ratings_df.melt(id_vars=['user'], var_name='product', value_name='rating')\n",
        "    ratings_df['product'] = ratings_df['product'].astype(int)\n",
        "\n",
        "    # Merge the ratings and movies dataframes\n",
        "    merged_df = pd.merge(ratings_df, movies_df.reset_index(), on='product')\n",
        "\n",
        "    # You can add additional preprocessing steps here based on your model's requirements\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "\n",
        "# function to get recommendations\n",
        "def get_recommendations(ratings_df, user_item_matrix, user_id):\n",
        "    # use FeatureHasher to reduce dimensionality\n",
        "    hasher = FeatureHasher(n_features=100, input_type='string')\n",
        "    hashed_features = hasher.transform(user_item_matrix.fillna(0).astype(str))\n",
        "\n",
        "    # calculate cosine similarity\n",
        "    user_similarity = cosine_similarity(hashed_features)\n",
        "    user_similarity_df = pd.DataFrame(user_similarity, index=ratings_df.index, columns=ratings_df.index)\n",
        "\n",
        "    # get similar users to our new user\n",
        "    similar_users = user_similarity_df[user_id].sort_values(ascending=False)\n",
        "\n",
        "    # get movie recommendations\n",
        "    similar_users_movies = user_itappendem_matrix.loc[similar_users.index]\n",
        "    recommended_movies = similar_users_movies.mean().sort_values(ascending=False)\n",
        "\n",
        "    return recommended_movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_user_ratings = {\n",
        "    0: 4,  # The new user rated movie with product ID 0 with a score of 4\n",
        "    10: 5,  # The new user rated movie with product ID 10 with a score of 5\n",
        "    20: 3  # The new user rated movie with product ID 20 with a score of 3\n",
        "}\n",
        "\n",
        "# add the new user to the dataset\n",
        "updated_ratings_df, new_user_id = add_new_user(ratings_df, new_user_ratings)\n",
        "\n",
        "# preprocess the updated dataset\n",
        "user_item_matrix = preprocess_data(updated_ratings_df, movies_df)\n",
        "\n",
        "# get recommendations for the new user\n",
        "recommended_movies = get_recommendations(updated_ratings_df, user_item_matrix, new_user_id)\n",
        "print(recommended_movies)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming the new user's id is the max userId in the existing ratings DataFrame plus 1\n",
        "new_user_id = ratings_df.index.max() + 1\n",
        "\n",
        "\n",
        "# Ratings provided by the new user (random data for demonstration)\n",
        "new_user_ratings = {\n",
        "    'userId': [new_user_id, new_user_id, new_user_id],\n",
        "    'movieId': [1, 2, 3],  # Movie IDs rated by the new user\n",
        "    'rating': [4.0, 3.5, 5.0],  # Ratings given by the new user\n",
        "    'timestamp': [datetime.timestamp(datetime.now())]*3  # Timestamps of the ratings\n",
        "}\n",
        "\n",
        "new_user_df = pd.DataFrame(new_user_ratings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recommendations = recommend_movies_for_new_user(model1, new_user_df, movies_df)\n",
        "print(\"Recommended movies for the new user:\", recommendations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lime\n",
        "import lime.lime_tabular\n",
        "import numpy as np\n",
        "\n",
        "# Subset the test data for user i\n",
        "test_user_i = test[test[\"user\"] == 0]\n",
        "\n",
        "# Define a function for model prediction\n",
        "def predict_fn(data):\n",
        "    return np.array([model1.predict([test_user_i[\"user\"], test_user_i[\"product\"], test_user_i[features], test_user_i[context]])])\n",
        "\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(train.values, feature_names=train.columns, class_names=[\"y\"], discretize_continuous=True)\n",
        "\n",
        "exp = explainer.explain_instance(test.iloc[0], predict_fn, num_features=5)\n",
        "\n",
        "exp.show_in_notebook(show_table=True, show_all=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# Use DeepExplainer to explain the output of the model\n",
        "explainer = shap.DeepExplainer(model1, [train[\"user\"], train[\"product\"], train[features], train[context]])\n",
        "\n",
        "# Calculate Shap values using a subset of the training data\n",
        "subset = train.sample(100)\n",
        "shap_values = explainer.shap_values([subset[\"user\"], subset[\"product\"], subset[features], subset[context]])\n",
        "\n",
        "# Plot the SHAP values\n",
        "shap.summary_plot(shap_values, subset)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
