{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zizi8Rl8UYRs",
        "outputId": "8b0e5f3b-7402-4828-d20c-0b36aec61fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_recommenders\n",
            "  Downloading tensorflow_recommenders-0.7.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_recommenders) (1.4.0)\n",
            "Requirement already satisfied: tensorflow>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_recommenders) (2.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.4.8)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.9.0->tensorflow_recommenders) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.9.0->tensorflow_recommenders) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (3.2.2)\n",
            "Installing collected packages: tensorflow_recommenders\n",
            "Successfully installed tensorflow_recommenders-0.7.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_recommenders\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "from typing import List, Union, Dict, Text\n",
        "from google.colab import files\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie = files.upload()\n",
        "user = files.upload()\n",
        "rating = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "LxQgG2tTtWCW",
        "outputId": "5c3225bd-38b9-4164-e5b4-9b94f0460fe5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2c1d458b-e279-4aca-b3c1-8265236a7702\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2c1d458b-e279-4aca-b3c1-8265236a7702\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving movies_cleaned.csv to movies_cleaned.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f8531904-c67c-4214-b8ea-56b31c7c8872\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f8531904-c67c-4214-b8ea-56b31c7c8872\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving users_cleaned.csv to users_cleaned.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-754f11af-cd29-496d-ac83-74c93ee2c31d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-754f11af-cd29-496d-ac83-74c93ee2c31d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ratings_cleaned.csv to ratings_cleaned.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = pd.read_csv(io.BytesIO(movie['movies_cleaned.csv']))\n",
        "users_df = pd.read_csv(io.BytesIO(user['users_cleaned.csv']))\n",
        "ratings_df = pd.read_csv(io.BytesIO(rating['ratings_cleaned.csv']))"
      ],
      "metadata": {
        "id": "K-fGj6pEtuhs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaD9Mqy1U7Hi"
      },
      "outputs": [],
      "source": [
        "#movies_df = pd.read_csv('data/movies_cleaned.csv')\n",
        "#users_df = pd.read_csv('data/users_cleaned.csv')\n",
        "#ratings_df = pd.read_csv('data/ratings_cleaned.csv' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w2yLukovZaYC"
      },
      "outputs": [],
      "source": [
        "# Merge all data into a single DataFrame\n",
        "merged_df = pd.merge(ratings_df, users_df, on='userId')\n",
        "merged_df = pd.merge(merged_df, movies_df, left_on='movieId', right_on='ml_movieId')\n",
        "\n",
        "merged_df['userId']=merged_df['userId'].astype(str)\n",
        "merged_df['Title']=merged_df['Title'].astype(str)\n",
        "\n",
        "# Convert the merged DataFrame to a TensorFlow Dataset\n",
        "ratings = tf.data.Dataset.from_tensor_slices(dict(merged_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oD-BdFRDZqIM"
      },
      "outputs": [],
      "source": [
        "# Select the basic features.\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"Title\"],\n",
        "    \"user_id\": x[\"userId\"],\n",
        "    \"user_rating\": x[\"rating\"],\n",
        "})\n",
        "movies = tf.data.Dataset.from_tensor_slices(movies_df[\"Title\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D74utrzwZtg8"
      },
      "outputs": [],
      "source": [
        "# Randomly shuffle data and split between train and test.\n",
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000)\n",
        "test = shuffled.skip(80_000).take(20_000)\n",
        "\n",
        "movie_titles = movies.batch(1_000)\n",
        "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
        "\n",
        "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
        "\n",
        "embedding_dimension = 32\n",
        "\n",
        "user_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_user_ids, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "movie_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_movie_titles, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kqXpRqn_ahjl"
      },
      "outputs": [],
      "source": [
        "class MovielensModel(tfrs.models.Model):\n",
        "    def __init__(self, user_model, movie_model, rating_weight: float, retrieval_weight: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.movie_model = movie_model\n",
        "        self.user_model = user_model\n",
        "\n",
        "        self.rating_model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(1),\n",
        "        ])\n",
        "\n",
        "        self.rating_task = tfrs.tasks.Ranking(\n",
        "            loss=tf.keras.losses.MeanSquaredError(),\n",
        "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
        "        )\n",
        "        self.retrieval_task = tfrs.tasks.Retrieval(\n",
        "            metrics=tfrs.metrics.FactorizedTopK(\n",
        "                candidates=movies.batch(128).map(self.movie_model)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.rating_weight = rating_weight\n",
        "        self.retrieval_weight = retrieval_weight\n",
        "\n",
        "    def call(self, features):\n",
        "        user_embeddings = self.user_model(features[\"user_id\"])\n",
        "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
        "\n",
        "        return (\n",
        "            user_embeddings,\n",
        "            movie_embeddings,\n",
        "            self.rating_model(tf.concat([user_embeddings, movie_embeddings], axis=1)),\n",
        "        )\n",
        "\n",
        "    def compute_loss(self, features, training=False):\n",
        "        ratings = features.pop(\"user_rating\")\n",
        "\n",
        "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
        "\n",
        "        rating_loss = self.rating_task(\n",
        "            labels=ratings,\n",
        "            predictions=rating_predictions,\n",
        "        )\n",
        "        retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
        "\n",
        "        return (\n",
        "            self.rating_weight * rating_loss + self.retrieval_weight * retrieval_loss\n",
        "        )\n",
        "\n",
        "    def recommend(self, user_id, k):\n",
        "        user_id_tensor = tf.convert_to_tensor([user_id])\n",
        "        user_embedding = self.user_model(user_id_tensor)\n",
        "        movie_embeddings = self.movie_model(unique_movie_titles)\n",
        "        scores = tf.linalg.matmul(user_embedding, movie_embeddings, transpose_b=True)\n",
        "        scores = tf.reshape(scores, (1, -1))  # Reshape scores tensor\n",
        "        top_k_movie_indices = tf.nn.top_k(scores, k=k).indices.numpy()[0]  # Update this line\n",
        "        return [unique_movie_titles[i] for i in top_k_movie_indices]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            \"user_model\": self.user_model,\n",
        "            \"movie_model\": self.movie_model,\n",
        "            \"rating_weight\": self.rating_weight,\n",
        "            \"retrieval_weight\": self.retrieval_weight\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J4ICbPHLtT4a"
      },
      "outputs": [],
      "source": [
        "def add_new_user_ratings(user_id: str, watched_movies: List[str], user_ratings: List[Union[int, float]]):\n",
        "    # Declare global variables at the beginning of the function\n",
        "    global ratings\n",
        "    global unique_user_ids\n",
        "\n",
        "    # Ensure the user is new\n",
        "    assert user_id not in unique_user_ids, \"The new user id already exists in the data.\"\n",
        "\n",
        "    # Ensure the movies exist in the dataset\n",
        "    for movie in watched_movies:\n",
        "        assert movie in unique_movie_titles, f\"The movie {movie} does not exist in the data.\"\n",
        "\n",
        "    # Convert user_ratings to integers\n",
        "    user_ratings = [int(rating) for rating in user_ratings]\n",
        "\n",
        "    # Create new user data\n",
        "    new_user_data = pd.DataFrame({\n",
        "        'user_id': [user_id] * len(watched_movies),\n",
        "        'movie_title': watched_movies,\n",
        "        'user_rating': user_ratings,\n",
        "    })\n",
        "\n",
        "    # Convert the DataFrame to a TensorFlow Dataset\n",
        "    new_ratings = tf.data.Dataset.from_tensor_slices(dict(new_user_data))\n",
        "\n",
        "    # Update the global 'ratings' variable\n",
        "    ratings = ratings.concatenate(new_ratings)\n",
        "\n",
        "    # Update the global 'unique_user_ids' variable\n",
        "    unique_user_ids = np.concatenate([unique_user_ids, np.array([user_id])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NfBq2QOVeycc"
      },
      "outputs": [],
      "source": [
        "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
        "cached_test = test.batch(4096).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XINx56H7tT4d"
      },
      "outputs": [],
      "source": [
        "# Define model checkpoints and early stopping\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"model_checkpoint\",\n",
        "    save_weights_only=True,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=3,\n",
        "    mode=\"min\",\n",
        "    restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX4FPitBfTG6",
        "outputId": "011991f1-98b5-4400-ab3d-584a597290b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 75s 7s/step - root_mean_squared_error: 2.2647 - factorized_top_k/top_1_categorical_accuracy: 1.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0014 - factorized_top_k/top_10_categorical_accuracy: 0.0030 - factorized_top_k/top_50_categorical_accuracy: 0.0152 - factorized_top_k/top_100_categorical_accuracy: 0.0300 - loss: 4.7081 - regularization_loss: 0.0000e+00 - total_loss: 4.7081 - val_root_mean_squared_error: 1.2681 - val_factorized_top_k/top_1_categorical_accuracy: 2.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0016 - val_factorized_top_k/top_10_categorical_accuracy: 0.0032 - val_factorized_top_k/top_50_categorical_accuracy: 0.0165 - val_factorized_top_k/top_100_categorical_accuracy: 0.0333 - val_loss: 1.5775 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.5775\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 60s 6s/step - root_mean_squared_error: 1.0875 - factorized_top_k/top_1_categorical_accuracy: 2.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0016 - factorized_top_k/top_10_categorical_accuracy: 0.0032 - factorized_top_k/top_50_categorical_accuracy: 0.0159 - factorized_top_k/top_100_categorical_accuracy: 0.0316 - loss: 1.1666 - regularization_loss: 0.0000e+00 - total_loss: 1.1666 - val_root_mean_squared_error: 1.0191 - val_factorized_top_k/top_1_categorical_accuracy: 3.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0017 - val_factorized_top_k/top_10_categorical_accuracy: 0.0038 - val_factorized_top_k/top_50_categorical_accuracy: 0.0177 - val_factorized_top_k/top_100_categorical_accuracy: 0.0350 - val_loss: 1.0270 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.0270\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 53s 5s/step - root_mean_squared_error: 0.9895 - factorized_top_k/top_1_categorical_accuracy: 2.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0019 - factorized_top_k/top_10_categorical_accuracy: 0.0038 - factorized_top_k/top_50_categorical_accuracy: 0.0186 - factorized_top_k/top_100_categorical_accuracy: 0.0353 - loss: 0.9784 - regularization_loss: 0.0000e+00 - total_loss: 0.9784 - val_root_mean_squared_error: 0.9904 - val_factorized_top_k/top_1_categorical_accuracy: 3.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0026 - val_factorized_top_k/top_10_categorical_accuracy: 0.0049 - val_factorized_top_k/top_50_categorical_accuracy: 0.0208 - val_factorized_top_k/top_100_categorical_accuracy: 0.0393 - val_loss: 0.9733 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9733\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 53s 5s/step - root_mean_squared_error: 0.9640 - factorized_top_k/top_1_categorical_accuracy: 4.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0030 - factorized_top_k/top_10_categorical_accuracy: 0.0058 - factorized_top_k/top_50_categorical_accuracy: 0.0235 - factorized_top_k/top_100_categorical_accuracy: 0.0419 - loss: 0.9299 - regularization_loss: 0.0000e+00 - total_loss: 0.9299 - val_root_mean_squared_error: 0.9755 - val_factorized_top_k/top_1_categorical_accuracy: 4.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0039 - val_factorized_top_k/top_10_categorical_accuracy: 0.0065 - val_factorized_top_k/top_50_categorical_accuracy: 0.0244 - val_factorized_top_k/top_100_categorical_accuracy: 0.0458 - val_loss: 0.9444 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9444\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 53s 5s/step - root_mean_squared_error: 0.9482 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0047 - factorized_top_k/top_10_categorical_accuracy: 0.0081 - factorized_top_k/top_50_categorical_accuracy: 0.0293 - factorized_top_k/top_100_categorical_accuracy: 0.0488 - loss: 0.9009 - regularization_loss: 0.0000e+00 - total_loss: 0.9009 - val_root_mean_squared_error: 0.9686 - val_factorized_top_k/top_1_categorical_accuracy: 0.0010 - val_factorized_top_k/top_5_categorical_accuracy: 0.0048 - val_factorized_top_k/top_10_categorical_accuracy: 0.0080 - val_factorized_top_k/top_50_categorical_accuracy: 0.0277 - val_factorized_top_k/top_100_categorical_accuracy: 0.0496 - val_loss: 0.9305 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9305\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 74s 7s/step - root_mean_squared_error: 0.9422 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0053 - factorized_top_k/top_10_categorical_accuracy: 0.0097 - factorized_top_k/top_50_categorical_accuracy: 0.0324 - factorized_top_k/top_100_categorical_accuracy: 0.0530 - loss: 0.8903 - regularization_loss: 0.0000e+00 - total_loss: 0.8903 - val_root_mean_squared_error: 0.9670 - val_factorized_top_k/top_1_categorical_accuracy: 0.0012 - val_factorized_top_k/top_5_categorical_accuracy: 0.0048 - val_factorized_top_k/top_10_categorical_accuracy: 0.0089 - val_factorized_top_k/top_50_categorical_accuracy: 0.0300 - val_factorized_top_k/top_100_categorical_accuracy: 0.0516 - val_loss: 0.9271 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9271\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 55s 6s/step - root_mean_squared_error: 0.9393 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0057 - factorized_top_k/top_10_categorical_accuracy: 0.0103 - factorized_top_k/top_50_categorical_accuracy: 0.0333 - factorized_top_k/top_100_categorical_accuracy: 0.0549 - loss: 0.8844 - regularization_loss: 0.0000e+00 - total_loss: 0.8844 - val_root_mean_squared_error: 0.9628 - val_factorized_top_k/top_1_categorical_accuracy: 9.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0048 - val_factorized_top_k/top_10_categorical_accuracy: 0.0091 - val_factorized_top_k/top_50_categorical_accuracy: 0.0308 - val_factorized_top_k/top_100_categorical_accuracy: 0.0525 - val_loss: 0.9191 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9191\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 56s 6s/step - root_mean_squared_error: 0.9338 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0058 - factorized_top_k/top_10_categorical_accuracy: 0.0102 - factorized_top_k/top_50_categorical_accuracy: 0.0338 - factorized_top_k/top_100_categorical_accuracy: 0.0555 - loss: 0.8739 - regularization_loss: 0.0000e+00 - total_loss: 0.8739 - val_root_mean_squared_error: 0.9563 - val_factorized_top_k/top_1_categorical_accuracy: 8.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0050 - val_factorized_top_k/top_10_categorical_accuracy: 0.0088 - val_factorized_top_k/top_50_categorical_accuracy: 0.0309 - val_factorized_top_k/top_100_categorical_accuracy: 0.0528 - val_loss: 0.9069 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9069\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 53s 5s/step - root_mean_squared_error: 0.9278 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0055 - factorized_top_k/top_10_categorical_accuracy: 0.0102 - factorized_top_k/top_50_categorical_accuracy: 0.0339 - factorized_top_k/top_100_categorical_accuracy: 0.0556 - loss: 0.8630 - regularization_loss: 0.0000e+00 - total_loss: 0.8630 - val_root_mean_squared_error: 0.9508 - val_factorized_top_k/top_1_categorical_accuracy: 8.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0052 - val_factorized_top_k/top_10_categorical_accuracy: 0.0088 - val_factorized_top_k/top_50_categorical_accuracy: 0.0311 - val_factorized_top_k/top_100_categorical_accuracy: 0.0535 - val_loss: 0.8969 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8969\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 56s 6s/step - root_mean_squared_error: 0.9232 - factorized_top_k/top_1_categorical_accuracy: 9.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0056 - factorized_top_k/top_10_categorical_accuracy: 0.0100 - factorized_top_k/top_50_categorical_accuracy: 0.0336 - factorized_top_k/top_100_categorical_accuracy: 0.0554 - loss: 0.8547 - regularization_loss: 0.0000e+00 - total_loss: 0.8547 - val_root_mean_squared_error: 0.9470 - val_factorized_top_k/top_1_categorical_accuracy: 8.5000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0050 - val_factorized_top_k/top_10_categorical_accuracy: 0.0089 - val_factorized_top_k/top_50_categorical_accuracy: 0.0310 - val_factorized_top_k/top_100_categorical_accuracy: 0.0531 - val_loss: 0.8901 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8901\n",
            "5/5 [==============================] - 9s 2s/step - root_mean_squared_error: 0.9470 - factorized_top_k/top_1_categorical_accuracy: 8.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0050 - factorized_top_k/top_10_categorical_accuracy: 0.0089 - factorized_top_k/top_50_categorical_accuracy: 0.0310 - factorized_top_k/top_100_categorical_accuracy: 0.0531 - loss: 0.8956 - regularization_loss: 0.0000e+00 - total_loss: 0.8956\n",
            "Retrieval top-100 accuracy: 0.053.\n",
            "Ranking RMSE: 0.947.\n"
          ]
        }
      ],
      "source": [
        "# Rating-focused model\n",
        "rating_model = MovielensModel(user_model, movie_model, rating_weight=1.0, retrieval_weight=0.0)\n",
        "rating_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "rating_model.fit(\n",
        "    cached_train,\n",
        "    epochs=10,\n",
        "    validation_data=cached_test,\n",
        "    callbacks=[checkpoint_callback, early_stopping_callback]\n",
        ")\n",
        "rating_metrics = rating_model.evaluate(cached_test, return_dict=True)\n",
        "print(f\"Retrieval top-100 accuracy: {rating_metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
        "print(f\"Ranking RMSE: {rating_metrics['root_mean_squared_error']:.3f}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyaqnwKefeny",
        "outputId": "b67e7189-6894-401f-dd44-6fbf83e66fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 56s 6s/step - root_mean_squared_error: 4.0090 - factorized_top_k/top_1_categorical_accuracy: 0.0022 - factorized_top_k/top_5_categorical_accuracy: 0.0252 - factorized_top_k/top_10_categorical_accuracy: 0.0593 - factorized_top_k/top_50_categorical_accuracy: 0.2732 - factorized_top_k/top_100_categorical_accuracy: 0.3503 - loss: 70234.5455 - regularization_loss: 0.0000e+00 - total_loss: 70234.5455 - val_root_mean_squared_error: 3.9476 - val_factorized_top_k/top_1_categorical_accuracy: 0.0041 - val_factorized_top_k/top_5_categorical_accuracy: 0.0337 - val_factorized_top_k/top_10_categorical_accuracy: 0.0741 - val_factorized_top_k/top_50_categorical_accuracy: 0.3595 - val_factorized_top_k/top_100_categorical_accuracy: 0.4988 - val_loss: 29471.0391 - val_regularization_loss: 0.0000e+00 - val_total_loss: 29471.0391\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 54s 6s/step - root_mean_squared_error: 3.9455 - factorized_top_k/top_1_categorical_accuracy: 0.0074 - factorized_top_k/top_5_categorical_accuracy: 0.0697 - factorized_top_k/top_10_categorical_accuracy: 0.1415 - factorized_top_k/top_50_categorical_accuracy: 0.5150 - factorized_top_k/top_100_categorical_accuracy: 0.6741 - loss: 69076.2500 - regularization_loss: 0.0000e+00 - total_loss: 69076.2500 - val_root_mean_squared_error: 3.8934 - val_factorized_top_k/top_1_categorical_accuracy: 0.0030 - val_factorized_top_k/top_5_categorical_accuracy: 0.0326 - val_factorized_top_k/top_10_categorical_accuracy: 0.0794 - val_factorized_top_k/top_50_categorical_accuracy: 0.3905 - val_factorized_top_k/top_100_categorical_accuracy: 0.5548 - val_loss: 29395.8086 - val_regularization_loss: 0.0000e+00 - val_total_loss: 29395.8086\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 54s 6s/step - root_mean_squared_error: 3.8945 - factorized_top_k/top_1_categorical_accuracy: 0.0125 - factorized_top_k/top_5_categorical_accuracy: 0.1221 - factorized_top_k/top_10_categorical_accuracy: 0.2209 - factorized_top_k/top_50_categorical_accuracy: 0.6188 - factorized_top_k/top_100_categorical_accuracy: 0.7692 - loss: 67592.7713 - regularization_loss: 0.0000e+00 - total_loss: 67592.7713 - val_root_mean_squared_error: 3.8482 - val_factorized_top_k/top_1_categorical_accuracy: 0.0015 - val_factorized_top_k/top_5_categorical_accuracy: 0.0255 - val_factorized_top_k/top_10_categorical_accuracy: 0.0710 - val_factorized_top_k/top_50_categorical_accuracy: 0.3929 - val_factorized_top_k/top_100_categorical_accuracy: 0.5594 - val_loss: 29563.1543 - val_regularization_loss: 0.0000e+00 - val_total_loss: 29563.1543\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 55s 6s/step - root_mean_squared_error: 3.8549 - factorized_top_k/top_1_categorical_accuracy: 0.0174 - factorized_top_k/top_5_categorical_accuracy: 0.1583 - factorized_top_k/top_10_categorical_accuracy: 0.2754 - factorized_top_k/top_50_categorical_accuracy: 0.6821 - factorized_top_k/top_100_categorical_accuracy: 0.8210 - loss: 66296.6136 - regularization_loss: 0.0000e+00 - total_loss: 66296.6136 - val_root_mean_squared_error: 3.8116 - val_factorized_top_k/top_1_categorical_accuracy: 0.0012 - val_factorized_top_k/top_5_categorical_accuracy: 0.0210 - val_factorized_top_k/top_10_categorical_accuracy: 0.0624 - val_factorized_top_k/top_50_categorical_accuracy: 0.3855 - val_factorized_top_k/top_100_categorical_accuracy: 0.5508 - val_loss: 29879.0898 - val_regularization_loss: 0.0000e+00 - val_total_loss: 29879.0898\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 55s 6s/step - root_mean_squared_error: 3.8240 - factorized_top_k/top_1_categorical_accuracy: 0.0193 - factorized_top_k/top_5_categorical_accuracy: 0.1817 - factorized_top_k/top_10_categorical_accuracy: 0.3131 - factorized_top_k/top_50_categorical_accuracy: 0.7242 - factorized_top_k/top_100_categorical_accuracy: 0.8539 - loss: 65250.1875 - regularization_loss: 0.0000e+00 - total_loss: 65250.1875 - val_root_mean_squared_error: 3.7830 - val_factorized_top_k/top_1_categorical_accuracy: 0.0012 - val_factorized_top_k/top_5_categorical_accuracy: 0.0177 - val_factorized_top_k/top_10_categorical_accuracy: 0.0569 - val_factorized_top_k/top_50_categorical_accuracy: 0.3769 - val_factorized_top_k/top_100_categorical_accuracy: 0.5445 - val_loss: 30253.8516 - val_regularization_loss: 0.0000e+00 - val_total_loss: 30253.8516\n",
            "5/5 [==============================] - 10s 2s/step - root_mean_squared_error: 3.8934 - factorized_top_k/top_1_categorical_accuracy: 0.0030 - factorized_top_k/top_5_categorical_accuracy: 0.0326 - factorized_top_k/top_10_categorical_accuracy: 0.0794 - factorized_top_k/top_50_categorical_accuracy: 0.3905 - factorized_top_k/top_100_categorical_accuracy: 0.5548 - loss: 32298.9115 - regularization_loss: 0.0000e+00 - total_loss: 32298.9115\n",
            "Retrieval top-100 accuracy: 0.555.\n",
            "Ranking RMSE: 3.893.\n"
          ]
        }
      ],
      "source": [
        "# Retrieval-focused model\n",
        "retrieval_model = MovielensModel(user_model, movie_model, rating_weight=0.0, retrieval_weight=1.0)\n",
        "retrieval_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "retrieval_model.fit(\n",
        "    cached_train,\n",
        "    epochs=10,\n",
        "    validation_data=cached_test,\n",
        "    callbacks=[checkpoint_callback, early_stopping_callback]\n",
        ")\n",
        "retrieval_metrics = retrieval_model.evaluate(cached_test, return_dict=True)\n",
        "print(f\"Retrieval top-100 accuracy: {retrieval_metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
        "print(f\"Ranking RMSE: {retrieval_metrics['root_mean_squared_error']:.3f}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3BiSfD0nfhaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "274bc7b6-3a44-4e17-f02a-0981e48cd0e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 56s 5s/step - root_mean_squared_error: 3.4208 - factorized_top_k/top_1_categorical_accuracy: 0.0162 - factorized_top_k/top_5_categorical_accuracy: 0.1513 - factorized_top_k/top_10_categorical_accuracy: 0.2756 - factorized_top_k/top_50_categorical_accuracy: 0.6995 - factorized_top_k/top_100_categorical_accuracy: 0.8388 - loss: 65982.9375 - regularization_loss: 0.0000e+00 - total_loss: 65982.9375 - val_root_mean_squared_error: 1.2313 - val_factorized_top_k/top_1_categorical_accuracy: 0.0012 - val_factorized_top_k/top_5_categorical_accuracy: 0.0166 - val_factorized_top_k/top_10_categorical_accuracy: 0.0514 - val_factorized_top_k/top_50_categorical_accuracy: 0.3552 - val_factorized_top_k/top_100_categorical_accuracy: 0.5244 - val_loss: 30649.3555 - val_regularization_loss: 0.0000e+00 - val_total_loss: 30649.3555\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 56s 6s/step - root_mean_squared_error: 1.1556 - factorized_top_k/top_1_categorical_accuracy: 0.0212 - factorized_top_k/top_5_categorical_accuracy: 0.1932 - factorized_top_k/top_10_categorical_accuracy: 0.3349 - factorized_top_k/top_50_categorical_accuracy: 0.7611 - factorized_top_k/top_100_categorical_accuracy: 0.8832 - loss: 64208.1328 - regularization_loss: 0.0000e+00 - total_loss: 64208.1328 - val_root_mean_squared_error: 1.1048 - val_factorized_top_k/top_1_categorical_accuracy: 0.0011 - val_factorized_top_k/top_5_categorical_accuracy: 0.0143 - val_factorized_top_k/top_10_categorical_accuracy: 0.0477 - val_factorized_top_k/top_50_categorical_accuracy: 0.3521 - val_factorized_top_k/top_100_categorical_accuracy: 0.5217 - val_loss: 31176.1367 - val_regularization_loss: 0.0000e+00 - val_total_loss: 31176.1367\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 65s 7s/step - root_mean_squared_error: 0.9672 - factorized_top_k/top_1_categorical_accuracy: 0.0223 - factorized_top_k/top_5_categorical_accuracy: 0.2044 - factorized_top_k/top_10_categorical_accuracy: 0.3550 - factorized_top_k/top_50_categorical_accuracy: 0.7811 - factorized_top_k/top_100_categorical_accuracy: 0.8969 - loss: 63508.9908 - regularization_loss: 0.0000e+00 - total_loss: 63508.9908 - val_root_mean_squared_error: 1.0656 - val_factorized_top_k/top_1_categorical_accuracy: 7.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0135 - val_factorized_top_k/top_10_categorical_accuracy: 0.0459 - val_factorized_top_k/top_50_categorical_accuracy: 0.3470 - val_factorized_top_k/top_100_categorical_accuracy: 0.5192 - val_loss: 31582.3906 - val_regularization_loss: 0.0000e+00 - val_total_loss: 31582.3906\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 54s 6s/step - root_mean_squared_error: 0.9426 - factorized_top_k/top_1_categorical_accuracy: 0.0244 - factorized_top_k/top_5_categorical_accuracy: 0.2115 - factorized_top_k/top_10_categorical_accuracy: 0.3681 - factorized_top_k/top_50_categorical_accuracy: 0.7935 - factorized_top_k/top_100_categorical_accuracy: 0.9061 - loss: 63056.0948 - regularization_loss: 0.0000e+00 - total_loss: 63056.0948 - val_root_mean_squared_error: 1.0629 - val_factorized_top_k/top_1_categorical_accuracy: 9.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0126 - val_factorized_top_k/top_10_categorical_accuracy: 0.0440 - val_factorized_top_k/top_50_categorical_accuracy: 0.3441 - val_factorized_top_k/top_100_categorical_accuracy: 0.5193 - val_loss: 31914.3926 - val_regularization_loss: 0.0000e+00 - val_total_loss: 31914.3926\n",
            "5/5 [==============================] - 10s 2s/step - root_mean_squared_error: 1.2313 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0166 - factorized_top_k/top_10_categorical_accuracy: 0.0514 - factorized_top_k/top_50_categorical_accuracy: 0.3552 - factorized_top_k/top_100_categorical_accuracy: 0.5244 - loss: 33736.4076 - regularization_loss: 0.0000e+00 - total_loss: 33736.4076\n",
            "Retrieval top-100 accuracy: 0.524.\n",
            "Ranking RMSE: 1.231.\n"
          ]
        }
      ],
      "source": [
        "# Balanced model\n",
        "balanced_model = MovielensModel(user_model, movie_model, rating_weight=1.0, retrieval_weight=1.0)\n",
        "balanced_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "balanced_model.fit(\n",
        "    cached_train,\n",
        "    epochs=10,\n",
        "    validation_data=cached_test,\n",
        "    callbacks=[checkpoint_callback, early_stopping_callback]\n",
        ")\n",
        "balanced_metrics = balanced_model.evaluate(cached_test, return_dict=True)\n",
        "print(f\"Retrieval top-100 accuracy: {balanced_metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
        "print(f\"Ranking RMSE: {balanced_metrics['root_mean_squared_error']:.3f}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating_model.save_weights('rating_model_weights')\n",
        "retrieval_model.save_weights('retrieval_model_weights')\n",
        "balanced_model.save_weights('balanced_model_weights')"
      ],
      "metadata": {
        "id": "p6X8pR20KbEH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = MovielensModel(user_model, movie_model, rating_weight=1.0, retrieval_weight=1.0)\n",
        "new_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "# Load the saved weights into the new model:\n",
        "new_model.load_weights('balanced_model_weights')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04I1PU2zsNhk",
        "outputId": "f46ea8e6-a696-4ee6-f8f6-d48eea40ef18"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fb42d518c10>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rec = new_model.recommend(\"42\",k=5)\n",
        "print(rec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fR55d1WsQkT",
        "outputId": "2cc13317-0feb-41a1-c2e8-537b28948cdc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[b'Alien: Resurrection', b'Demolition Man', b'The Fifth Element', b'Star Trek VI: The Undiscovered Country', b'The Day the Earth Stood Still']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "98ieQ38btT4m"
      },
      "outputs": [],
      "source": [
        "def get_unique_movie_title(movie_title):\n",
        "    for index, unique_title in enumerate(unique_movie_titles):\n",
        "        # Convert unique_title to string and remove the 'b' prefix and single quotes\n",
        "        unique_title_str = str(unique_title)[2:-1]\n",
        "        if movie_title == unique_title_str:\n",
        "            return index\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9m1h0LQtT4n",
        "outputId": "3f4e5c82-2496-4d8c-de0b-102dab447c06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The corresponding unique title index for '8 Seconds' is 20.\n"
          ]
        }
      ],
      "source": [
        "movie_title = '8 Seconds'\n",
        "unique_title_index = get_unique_movie_title(movie_title)\n",
        "if unique_title_index is not None:\n",
        "    print(f\"The corresponding unique title index for '{movie_title}' is {unique_title_index}.\")\n",
        "else:\n",
        "    print(f\"No matching unique title found for '{movie_title}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyz8VTB_tT4o"
      },
      "outputs": [],
      "source": [
        "m1 = get_unique_movie_title('8 Seconds')\n",
        "m2 = get_unique_movie_title('The Lion King')\n",
        "m3 = get_unique_movie_title('The Shawshank Redemption')\n",
        "m4 = get_unique_movie_title('The Godfather')\n",
        "m5 = get_unique_movie_title('Toy Story')\n",
        "m6 = get_unique_movie_title('The Matrix')\n",
        "m7 = get_unique_movie_title('The Terminator')\n",
        "m8 = get_unique_movie_title('Get Shorty')\n",
        "m9 = get_unique_movie_title('The Silence of the Lambs')\n",
        "m10 = get_unique_movie_title('The Usual Suspects')\n",
        "\n",
        "\n",
        "# Add a new user's ratings\n",
        "add_new_user_ratings(\n",
        "    user_id=\"new_user_12\",\n",
        "    watched_movies=[\n",
        "        unique_movie_titles[m1],\n",
        "        unique_movie_titles[m2],\n",
        "        unique_movie_titles[m3],\n",
        "        unique_movie_titles[m4],\n",
        "        unique_movie_titles[m5],\n",
        "        unique_movie_titles[m6],\n",
        "        unique_movie_titles[m7],\n",
        "        unique_movie_titles[m8],\n",
        "        unique_movie_titles[m9],\n",
        "        unique_movie_titles[m10],\n",
        "    ],\n",
        "    user_ratings=[2,5,3.5,4,2,3,1.5,5,4.5,4 ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_for_new_user(user_id, k):\n",
        "    # If the user is new, recommend the top k most popular movies\n",
        "    if user_id not in unique_user_ids:\n",
        "        popular_movie_ids = ratings_df['movieId'].value_counts().index[:k]\n",
        "        popular_movie_titles = movies_df[movies_df['movieId'].isin(popular_movie_ids)]['Title'].tolist()\n",
        "        return popular_movie_titles\n",
        "\n",
        "    # Otherwise, use the existing recommendation method\n",
        "    else:\n",
        "        recommendations = balanced_model.recommend(user_id, k)\n",
        "        return [unique_movie_titles[i] for i in recommendations]\n"
      ],
      "metadata": {
        "id": "AfO1qG7nLLuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"42\" and \"Dances with Wolves (1990)\" with valid user_id and movie_title from your data\n",
        "user_id = \"42\"  # Replace with a valid user_id\n",
        "recommendations = balanced_model.recommend(user_id, k=5)\n",
        "print(f\"Top 5 movie recommendations for user {user_id}: {recommendations}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "008t0D7_et9x",
        "outputId": "858f377e-7f6f-468a-fd6a-19688d33374b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 movie recommendations for user 42: [b'Alien: Resurrection', b'Demolition Man', b'The Fifth Element', b'Star Trek VI: The Undiscovered Country', b'The Day the Earth Stood Still']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"42\" and \"Dances with Wolves (1990)\" with valid user_id and movie_title from your data\n",
        "user_id = \"42\"  # Replace with a valid user_id\n",
        "recommendations1 = rating_model.recommend(user_id, k=5)\n",
        "print(f\"Top 5 movie recommendations for user {user_id}: {recommendations1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ENa8JqYKCeU",
        "outputId": "76c13ad7-6783-417d-ef2f-097f26ff60f8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 movie recommendations for user 42: [b'Alien: Resurrection', b'Demolition Man', b'The Fifth Element', b'Star Trek VI: The Undiscovered Country', b'The Day the Earth Stood Still']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"42\" and \"Dances with Wolves (1990)\" with valid user_id and movie_title from your data\n",
        "user_id = \"42\"  # Replace with a valid user_id\n",
        "recommendations2 = retrieval_model.recommend(user_id, k=5)\n",
        "print(f\"Top 5 movie recommendations for user {user_id}: {recommendations2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-4_4BHKKH-C",
        "outputId": "a92c2e19-40b6-43ef-aacb-3a8ca5d6fde8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 movie recommendations for user 42: [b'Alien: Resurrection', b'Demolition Man', b'The Fifth Element', b'Star Trek VI: The Undiscovered Country', b'The Day the Earth Stood Still']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}